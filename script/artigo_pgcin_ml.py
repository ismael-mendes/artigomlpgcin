# -*- coding: utf-8 -*-
"""Artigo PGCIN ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O168ViMlcTPrpOGJKxJyd2ZFU3ss4tJ_

# Importação de dados
"""

#importar as bibliotecas
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from collections import OrderedDict

#carrega o dataset
dataset = pd.read_excel('/content/drive/MyDrive/PGCIN-UFSC/PCI410068 Machine Learning e Deep Learning/bibliometrics_database.xlsx')
dataset.head(2)

"""# Tratamento dos dados"""

#elimina primeiro do dataset os registros sem a data de publicação e os três outliers (+ de )
dataset = dataset.sort_values('Publication Year', ascending=0)
dataset = dataset.drop(dataset[dataset['Publication Year'].isnull()].index)
dataset = dataset.reset_index()
dataset.head(3)

#a variável dependente será o número médio de citações por ano (citation count) ao invés da contagem de citações (Times Cited, All Databases)
ano = 2021 - dataset['Publication Year']
ano = ano.replace(0,1)
tc = dataset.iloc[:,32:33]
tc = tc.to_numpy()

Y = [] 
i = 0
while (i < len(ano)): 
        Y.append(tc[i]//ano[i])
        i+=1

Y = pd.DataFrame(Y)
Y.columns = ['Citation Count']
Y#.head(3)

#contagem de autores e nome do autor (Author Full Names)
autores = dataset.iloc[:,6:7]

X1 = pd.DataFrame(autores['Author Full Names'].str.split(';').str.len()) #conta os autores por quantidade de ; + 1
X1.columns = ['Number of authors']
X1.head(3)

autores2 = autores['Author Full Names'].str.split(';', expand=True) #divide os autores em colunas
#autores2

lista = pd.Series(autores2.values.ravel('F')) #reorganiza o array em uma coluna só
lista.sort_values(0,inplace=True, ascending=True,ignore_index=True) #ordena os valores em ordem alfabética resetando o index
lista = pd.unique(lista).tolist() #remove os nomes duplicados
#lista

busca = autores2[0].tolist() #gera uma lista apenas com o primeiro autor
#busca

#armazena o index da lista de autores a partir do índice localizado na lista dos nomes dos primeiros autores
X2 = [] 
i = 0
while (i < len(busca)): 
    if (lista.count(busca[i]) > 0): 
        k = lista.index(busca[i])
        X2.append(k) 
    else:
        X2.append(None)
    i += 1

X2 = pd.DataFrame(X2)
X2.columns = ['First Author Position']
X2.head(3)

#Número de palavras no título (Article Title)
titulos = dataset.iloc[:,9:10]
titulos


X3 = pd.DataFrame(titulos['Article Title'].str.split().str.len())
X3.columns = ['Number of title words']
X3.head(3)

#Número de palavras no abstract
abstract = dataset.iloc[:,22:23]
#abstract

X4 = pd.DataFrame(abstract['Abstract'].str.split().str.len()).replace(np.nan, 0)
X4.columns = ['Number of abstract words']
X4.head(3)

#Periódico onde foi publicado (Source Title)
lista = dataset.iloc[:,10:11]
#lista

lista = pd.Series(lista.values.ravel('F')) #garante que o array é unidimensional
lista.sort_values(0,inplace=True, ascending=True,ignore_index=True) #ordena os valores em ordem alfabética resetando o index
lista = pd.unique(lista).tolist() #remove os nomes duplicados
#lista

#obtem o índice do nome do periódico na lista de periódicos (posição em ordem alfabética)
busca = dataset.iloc[:,10:11].values#.tolist()
busca


X5 = [] 
i = 0
while (i < len(busca)): 
    if (lista.count(busca[i]) > 0): 
        k = lista.index(busca[i])
        X5.append(k) 
    else:
        X5.append(None)
    i += 1

#armazena o index da lista de autores a partir do índice localizado na lista dos nomes dos primeiros autores
X5 = pd.DataFrame(X5)
X5.columns = ['Journal']
X5#.head(3)

#Quantidade de citações realizadas (Cited Reference Count)
X6 = dataset.iloc[:,31:32]
X6.head(3)

#Ano da publicação (Publication Year)
X7 = dataset.iloc[:,45:46]
X7 = X7.replace({np.nan: None})
X7.head(3)

#É parte de número especial? (Special Issue)
X8 = dataset.iloc[:,50:51]
#X8

X8 = pd.Series(X8['Special Issue']).str.replace('SI', '1').replace(np.nan, 0)
X8.columns = ['Special Issue']

X8.head(3)

#Contagem de páginas (Number of Pages)
X9 = dataset.iloc[:,58:59]
X9.head(3)

#juntar as variáveis independentes em um só dataset
X = pd.concat([X1,X2,X3,X4,X5,X6,X7,X8,X9], axis=1)
#X = X.reset_index()
#X.sort_values('Publication Year',inplace=True, ascending=False,ignore_index=True)
X.head(3)
#X.to_csv('/content/drive/MyDrive/PGCIN-UFSC/PCI410068 Machine Learning e Deep Learning/dados_predicao_exportados_colab.csv')

#converte em arrays
type(X) #retorna o tipo
X = X.values
Y = Y.values
type(X) #retorna o tipo, agora array

#cria primeiro uma estratificação das citações por quartis para os modelos por classificação

#quartil	inicio	fim
#Q1	    0	      2
#Q2	    2	      11,5
#Q3	    11,5	  31,25
#Q4	    31,25	  1376

Q = [] 
i = 0
while (i < len(Y)): 
        if Y[i] >= 0 and Y[i] < 2: 
          Q.append('1') #Q1
        elif Y[i] >= 2 and Y[i] < 12:
          Q.append('2') #Q2
        elif Y[i] >= 12 and Y[i] < 31:
          Q.append('3') #Q3
        elif Y[i] >= 31:
          Q.append('4') #Q4
        i+=1

Q = pd.DataFrame(Q).astype({0: 'int32'})
Q.columns = ['Citation Count Quartile']
Q#.head(3)
Q.value_counts()
Q = Q.values

#np.any(np.isnan(X4))
#np.isfinite(X4.all())

"""# Exploração dos dados"""

Xex = pd.concat([X1,X2,X3,X4,X5,X6,X7,X8,X9], axis=1)
Xex.describe()

Yex = pd.DataFrame(Y, columns = ['Citation count'])
Yex.describe()

Xex.info()

Yex.info()

allvar = pd.concat([Yex,X1,X2,X3,X4,X5,X6,X7,X8,X9], axis=1)
allvar.corr('pearson')

allvar.corr('spearman')

import seaborn as sns   
sns.set_style('darkgrid')
sns.distplot(Xex)
sns.scatterplot(data=allvar, x="Publication Year", y="Number of authors")
X1

#First Author Position
sns.distplot(X2)

#Number of title words
sns.distplot(X3)

#Number of abstract words
sns.distplot(X4)

#Journal
sns.distplot(X5)

#Cited Reference Count
sns.distplot(X6)

#Publication Year
sns.distplot(X7)

#Special Issue
sns.distplot(X8)

#Number of Pages
sns.distplot(X9)

#Citation count
sns.distplot(Y)

"""# Predição por Regressão Linear Multivariada"""

#separa as bases de treinamento e teste
from sklearn.model_selection import train_test_split  
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state = 1) #80% para treino e 20% para testes com amostra aleatória
#x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.34, random_state = 1) #34% para testes com amostra dos anos de 2018 até 2021

#treina a base de dados
from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(x_train, y_train)

#imprime coeficiente e intercepto
regressor.coef_, regressor.intercept_

#testar o modelo predizendo valores a partir da base de testes
y_pred = regressor.predict(x_test)
#y_pred

#verifica a acurácia do modelo com o r2
from sklearn.metrics import r2_score
print(r2_score(y_test,y_pred))

#verifica o score de variância
from sklearn.metrics import explained_variance_score
print(explained_variance_score(y_test, y_pred))

"""#Predição por Regressão Polinomial"""

#separa as bases de treinamento e teste
from sklearn.model_selection import train_test_split  
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state = 1) #80% para treino e 20% para testes com amostra aleatória

#transforma os valores em função polinomial h(θ)=θ0 + θ1X^1 + θ2X^2 + θ3X^3 .... e treina o modelo
from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures(degree = 2)

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()

x_poly = poly.fit_transform(x_train)
#x_poly

#imprime coeficiente e intercepto
regressor.fit(x_poly, y_train)

#testar o modelo predizendo valores a partir da base de testes
x_test_poly = poly.fit_transform(x_test)
y_pred = regressor.predict(x_test_poly)

#TODO: como avaliar acurácia da regressão polinomial? r2 não faz sentido já que não é uma reta. Não consegui descobrir.
from sklearn.metrics import mean_squared_error, r2_score
rmse = np.sqrt(mean_squared_error(y_test,y_pred))
r2 = r2_score(y_test,y_pred)
print(rmse)
print(r2)

"""#Predição com Regressão Logística"""

#recria X e Y (teste)
X = Xex #pd.concat([X1,X2,X3,X4,X5,X6,X7,X8,X9], axis=1)
Y = Yex

#separa as bases de treinamento e teste
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(X, Q, test_size=0.2, random_state = 1) #20% para testes com amostra aleatória

#feature scalling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

#treina os dados para classificação com regressão logística
from sklearn.linear_model import LogisticRegression
logclassifier = LogisticRegression(random_state=0,max_iter=500)
logclassifier.fit(x_train, y_train.ravel())#.values.ravel())
y_pred_log = logclassifier.predict(x_test)

#agora com SVM
from sklearn.svm import SVC
svmclassifier = SVC(kernel = 'rbf', random_state = 0)
svmclassifier.fit(x_train, y_train.ravel())#.values.ravel())
y_pred_svm = svmclassifier.predict(x_test)

#matriz de confusão
from sklearn.metrics import confusion_matrix
cmlog = confusion_matrix(y_test, y_pred_log)

from sklearn.metrics import confusion_matrix
cmsvm = confusion_matrix(y_test, y_pred_svm)

#acurácia com regressão logística/svm
from sklearn.metrics import accuracy_score
print(accuracy_score(y_test, y_pred_log))
print(accuracy_score(y_test, y_pred_svm))

#recall com regressão logística/svm
from sklearn.metrics import recall_score
print(recall_score(y_test, y_pred_log, average=None))
print(recall_score(y_test, y_pred_svm, average=None))

#precisão com decision tree
from sklearn.metrics import precision_score
print(precision_score(y_test, y_pred_log, average=None))
print(precision_score(y_test, y_pred_svm, average=None))

#f-score com decision tree
from sklearn.metrics import f1_score
print(f1_score(y_test, y_pred_log, average=None))
print(f1_score(y_test, y_pred_svm, average=None))

#faz relatório completo
from sklearn.metrics import classification_report
target_names = ['Q1', 'Q2', 'Q3', 'Q4']
print(classification_report(y_test, y_pred_log, target_names=target_names))
print(classification_report(y_test, y_pred_svm, target_names=target_names))



"""#Predição com Decision Tree"""

#pd.crosstab(index=allvar['Citation count'], columns='count', )
#allvar.to_csv('/content/drive/MyDrive/PGCIN-UFSC/PCI410068 Machine Learning e Deep Learning/dados_predicao_exportados_colab_antes_dt.csv')

#recria X e Y (teste)
X = Xex
#Xdt = pd.concat([X1,X2,X3,X4,X5,X6,X7,X8,X9], axis=1)
Y = Yex.values

#separa as bases de treinamento e teste
from sklearn.model_selection import train_test_split  
x_train, x_test, y_train, y_test = train_test_split(X, Q, test_size=0.2, random_state = 1) #80% para treino e 20% para testes com amostra aleatória

from sklearn.tree import DecisionTreeRegressor
regressor = DecisionTreeRegressor(random_state = 1)
regressor.fit(x_train,y_train)

#qual será o valor para uma pessoa na posição 6.5?
y_pred = regressor.predict(x_test)
y_pred

#matriz de confusão
from sklearn.metrics import confusion_matrix
cmlog = confusion_matrix(y_test, y_pred)
cmlog

#acurácia com decision tree
from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred)

#recall com decision tree
from sklearn.metrics import recall_score
recall_score(y_test, y_pred, average=None)

#precisão com decision tree
from sklearn.metrics import precision_score
precision_score(y_test, y_pred, average=None)

#f-score com decision tree
from sklearn.metrics import f1_score
f1_score(y_test, y_pred, average=None)

#faz relatório completo
from sklearn.metrics import classification_report
target_names = ['Q1', 'Q2', 'Q3', 'Q4']
print(classification_report(y_test, y_pred, target_names=target_names))

from sklearn import tree

fnames = ['Number of authors','First Author Position','Number of title words', 'Number of abstract words', 'Journal', 'Cited Reference Count', 'Publication Year', 'Special Issue', 'Number of Pages']
target_names = ['Q1', 'Q2', 'Q3', 'Q4']

plt.figure(figsize=(12,12))
tree.plot_tree(regressor, feature_names=fnames, class_names=target_names, filled=True, max_depth=1)

#of = '/content/drive/MyDrive/PGCIN-UFSC/PCI410068 Machine Learning e Deep Learning/decistion_tree.png'
#tree.export_graphviz(regressor, feature_names=fnames, class_names=target_names, filled=True, max_depth=3, out_file=of)

#TODO: descobrir como exportar com tamanho legível

"""##Fim"""